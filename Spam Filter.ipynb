{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our goal is to write a program that classifies new messages with an accuracy greater than 80%. We expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll use a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and can be downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "### Summary of Results\n",
    "We created a highly accurate spam filter that achieved an accuracy of 98.29%, almost 20% higher than our goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset\n",
    "We'll start by reading in the dataset and do a quick exploration of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "sms = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"Label\", \"SMS\"])\n",
    "\n",
    "# Quick exploration of the data\n",
    "print(sms.shape)\n",
    "display(sms.head())\n",
    "display(sms.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    0\n",
       "SMS      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.isnull().sum() # No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of spam and non-spam messages in our dataset\n",
    "sms[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 87% of the messages are ham and the remaining 13% are spam. This sample looks representative, since in practice most messages people receive are ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Set\n",
    "We'll now split our dataset into a training set and a test set, where the training set accounts for 80% of the data and the test set for the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "sms_randomized = sms.sample(frac=1, random_state=1) # frac: fraction of axis items to return\n",
    "\n",
    "# Calculate index for splitting\n",
    "index = round(len(sms_randomized) * 0.8)\n",
    "\n",
    "# Split into training and test sets\n",
    "training_set = sms_randomized[:index].reset_index(drop=True)\n",
    "test_set = sms_randomized[index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now analyze the percentage of spam and ham messages in each training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set percentage of spam and non-spam messages\n",
    "training_set[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set percentage of spam and non-spam messages\n",
    "test_set[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training and test sets seem to have percentages close to what we have in the full dataset--87% ham and 13% spam. Let's now move on to cleaning the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "We'll need to perform a bit of data cleaning first before we can calculate all the probabilities required by the algorithm. We'll need to transform the dataset in a format that will allow us to extract the information we need.\n",
    "\n",
    "We'll essentially be transforming the `SMS` column into multiple new columns, where each column represents a unique word from the vocabulary. More specifically, each column will show the frequency of that unique word for any given message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter Case and Punctuation\n",
    "We'll begin with removing punctuations and bringing every letter to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         yep  by the pretty sculpture\n",
       "1        yes  princess  are you going to make me moan \n",
       "2                           welp apparently he retired\n",
       "3                                              havent \n",
       "4    i forgot 2 ask ü all smth   there s a card on ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[\"SMS\"] = (training_set[\"SMS\"].str.replace(\"\\W\", \" \", regex=True) # \\W :\n",
    "                                        .str.lower())                    # NON digit/uppercase/lowercase/underscore\n",
    "training_set[\"SMS\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary\n",
    "We'll now create a list containing all the unique words from our training set, where each word is represented as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[\"SMS\"] = training_set[\"SMS\"].str.split()\n",
    "\n",
    "# Append all words in the training set messages to vocabulary (contains duplicates)\n",
    "vocabulary = []\n",
    "for message in training_set[\"SMS\"]:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# Remove duplicate words in vocabulary by converting our List into Set, then convert it back to List\n",
    "vocabulary = list(sorted(set(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7,783 unique words in all the messages from our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Training Set\n",
    "We'll now use `vocabulary` to transform the training dataset. We'll initialize a Dictionary where each key, value pair corresponds to a unique word from `vocabulary` and a List[ints] of length `training_set`. The indices in the List corresponds to the row indices in `training_set`, so each element in the List represents the number of times the unique word showed up in the SMS in `training_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary where each key is a unique word from the vocabulary\n",
    "# and each value is a list of length training_set.\n",
    "# Indices in the list correspond to the row indices in training_set.\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set[\"SMS\"]) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set[\"SMS\"]):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "   ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0  ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1  ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2  ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3  ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4  ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Dictionary to DataFrame where the keys are on the column\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02  ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0  ...       0    0          0   \n",
       "1       0             0     0            0   0  ...       0    0          0   \n",
       "2       0             0     0            0   0  ...       0    0          0   \n",
       "3       0             0     0            0   0  ...       0    0          0   \n",
       "4       0             0     0            0   0  ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the training set and the word counts DataFrame, both share the same row axis\n",
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Constants First\n",
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter.\n",
    "\n",
    "The Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages.\n",
    "\n",
    "$$ P(Spam|w_1,w_2,...,w_n) ∝ P(Spam) \\cdot \\prod_{i=1}^{n} P(w_i|Spam) $$\n",
    "$$ P(Ham|w_1,w_2,...,w_n) ∝ P(Ham) \\cdot \\prod_{i=1}^{n} P(w_i|Ham) $$\n",
    "where\n",
    "$$ P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{vocabulary}} $$\n",
    "$$ P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{vocabulary}} $$\n",
    "\n",
    "Note that: \n",
    "* $N_{Spam}$ is the total number of words in all the spam messages.\n",
    "* $N_{Ham}$ is the total number of words in all the non-spam messages.\n",
    "* $N_{vocabulary}$ is the total number of words in the vocabulary.\n",
    "* $N_{w_i|Spam}$ is the number of times the word $w_i$ occurs in all the spam messages.\n",
    "* $N_{w_i|Ham}$ is the number of times the word $w_i$ occurs in all the ham messages.\n",
    "\n",
    "We'll also use Laplace smoothing ($\\alpha = 1$).\n",
    "\n",
    "We'll now calculate the constants: $P(Spam), \\ P(Ham), \\ N_{Spam}, \\ N_{Ham}, \\ N_{vocabulary}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the spam and non-spam messages in the training set\n",
    "spam_msgs = training_set_clean[training_set_clean[\"Label\"] == \"spam\"]\n",
    "ham_msgs = training_set_clean[training_set_clean[\"Label\"] == \"ham\"]\n",
    "\n",
    "# Probability that a message is spam/non-spam in the training set\n",
    "p_spam = len(spam_msgs) / len(training_set_clean)\n",
    "p_ham = len(ham_msgs) / len(training_set_clean)\n",
    "\n",
    "# Total number of words in all the spam/non-spam messages\n",
    "n_spam = (spam_msgs[\"SMS\"].apply(len)).sum()\n",
    "n_ham = (ham_msgs[\"SMS\"].apply(len)).sum()\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Parameters\n",
    "Now that we have the constant terms calculated above, we'll now calculate for the parameters\n",
    "$$ P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{vocabulary}} $$\n",
    "$$ P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{vocabulary}} $$\n",
    "for each word $w_i$ in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parameters in dictionaries\n",
    "# where each key is a unique word in `vocabulary` and each value is initialized with 0\n",
    "spam_params = dict.fromkeys(vocabulary, 0)\n",
    "ham_params = dict.fromkeys(vocabulary, 0)\n",
    "\n",
    "for word in vocabulary:\n",
    "    # Number of times the word occurs in all spam messages\n",
    "    n_w_given_spam = spam_msgs[word].sum()\n",
    "    # Probability the word shows up given that a message is spam\n",
    "    p_w_given_spam = (n_w_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    # Store the probability with the corresponding word in the spam dictionary \n",
    "    spam_params[word] = p_w_given_spam\n",
    "    \n",
    "    #Same idea as above for non-spam\n",
    "    n_w_given_ham = ham_msgs[word].sum()\n",
    "    p_w_given_ham = (n_w_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    ham_params[word] = p_w_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying a New Message\n",
    "Now that we have all the parameters calculated, we can now create the spam filter. \n",
    "\n",
    "Recall that the spam filter utilizes these probabilities:\n",
    "$$ P(Spam|w_1,w_2,...,w_n) ∝ P(Spam) \\cdot \\prod_{i=1}^{n} P(w_i|Spam) $$\n",
    "$$ P(Ham|w_1,w_2,...,w_n) ∝ P(Ham) \\cdot \\prod_{i=1}^{n} P(w_i|Ham) $$\n",
    "and we've finished calculating for $$ P(Spam), P(Ham), P(w_i|Spam), P(w_i|Ham) $$\n",
    "stored in `p_spam`, `p_ham`, `spam_params`, `ham_params` respectively.\n",
    "\n",
    "\n",
    "The spam filter is a function that:\n",
    "* Takes in as input a new message ($w_1, w_2, ..., w_n$).\n",
    "* Calculates $P(Spam|w_1, w_2, ..., w_n) \\ and \\ P(Ham|w_1, w_2, ..., w_n$).\n",
    "* Compares the values of $P(Spam|w_1, w_2, ..., w_n) \\ and \\  P(Ham|w_1, w_2, ..., w_n$), and:\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as ham.\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) < P(Spam|w_1, w_2, ..., w_n$), then the message is classified as spam.\n",
    "    * If $P(Ham|w_1, w_2, ..., w_n) = P(Spam|w_1, w_2, ..., w_n$), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \"\"\"\n",
    "    Prints the probabilities that the message is spam/non-spam\n",
    "    and the classification (spam/non-spam/need human help).\n",
    "    \n",
    "    Parameters:\n",
    "        message(str):The string to classify.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean message, transform to List[strs]\n",
    "    message = (message.replace(\"\\W\", \" \")\n",
    "                      .lower()\n",
    "                      .split())\n",
    "    \n",
    "    # Initialize probabilities with constants\n",
    "    p_spam_given_msg = p_spam \n",
    "    p_ham_given_msg = p_ham\n",
    "    \n",
    "    # Look up each word in the message in the parameter dictionaries \n",
    "    # Looks up the calculation of the probability the word shows up given that a message is spam/non-spam\n",
    "    #                         and the probability the word shows up given that a message is non-spam\n",
    "    for word in message:\n",
    "        if word in spam_params:\n",
    "            p_spam_given_msg *= spam_params[word]\n",
    "        if word in ham_params:\n",
    "            p_ham_given_msg *= ham_params[word]\n",
    "    \n",
    "    # Prints probabilities and classification\n",
    "    print(\"P(Spam|message):\", p_spam_given_msg)\n",
    "    print(\"P(Ham|message):\", p_ham_given_msg)\n",
    "    if p_ham_given_msg > p_spam_given_msg:\n",
    "        print(\"Label: Ham\")\n",
    "    elif p_ham_given_msg < p_spam_given_msg:\n",
    "        print(\"Label: Spam\")\n",
    "    else:\n",
    "        print(\"Equal probabilities. Have a human classify this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.8375885649658594e-10\n",
      "P(Ham|message): 2.607764643641013e-14\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify(\"YOU WON!!! Claim your prize @ www.jfzhul.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.462438934624288e-24\n",
      "P(Ham|message): 2.968179728663378e-23\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Secret party tonight! I'll text u the address l8r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Spam Filter's Accuracy\n",
    "The results above look promising. Let's now apply our spam filter to the test set, which has 1,114 messages. \n",
    "\n",
    "Let's modify our `classify()` function to return labels instead of printing them, apply the function to the test set, and calculate the accuracy of the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \"\"\"\n",
    "    Returns the classification label(spam/non-spam/need human help) of the message.\n",
    "    \n",
    "    Parameters:\n",
    "        message(str):The string to classify.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean message, transform to List[strs]\n",
    "    message = (message.replace(\"\\W\", \" \")\n",
    "                      .lower()\n",
    "                      .split())\n",
    "    \n",
    "    # Initialize probabilities with constants\n",
    "    p_spam_given_msg = p_spam \n",
    "    p_ham_given_msg = p_ham\n",
    "    \n",
    "    # Look up each word in the message in the parameter dictionaries \n",
    "    # Looks up the calculation of the probability the word shows up given that a message is spam\n",
    "    #                         and the probability the word shows up given that a message is non-spam\n",
    "    for word in message:\n",
    "        if word in spam_params:\n",
    "            p_spam_given_msg *= spam_params[word]\n",
    "        if word in ham_params:\n",
    "            p_ham_given_msg *= ham_params[word]\n",
    "    \n",
    "    # Return classification\n",
    "    if p_ham_given_msg > p_spam_given_msg:\n",
    "        return \"ham\"\n",
    "    elif p_ham_given_msg < p_spam_given_msg:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"needs human classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our function to the test set and record the labels on a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"predicted\"] = test_set[\"SMS\"].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the predicted values with the true values to measure the accuracy of our spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1095\n",
      "Incorrect: 19\n",
      "0.9829443447037702\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "for row in test_set.iterrows(): # Iterates over DataFrame rows as (index, Series) pairs\n",
    "    row = row[1]                # We're not interested in the index\n",
    "    correct += row[\"Label\"] == row[\"predicted\"]\n",
    "    \n",
    "accuracy = correct/total\n",
    "\n",
    "print(\"Correct:\", correct)\n",
    "print(\"Incorrect:\", total - correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is about 98.29%, which is excellent. Our spam filter looked at 1,114 messages it's never seen in training and correctly classified 1,095 of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we managed to build a spam filter for SMS messages using multinomial Naive Bayes algorithm. We originally aimed for an accuracy over 80%, and we managed to surpass that. The spam filter had an accuracy of 98.29% on the test set, which is an excellent result.\n",
    "\n",
    "Next steps include making the filtering process more complex\n",
    "* by making the algorithm more sensitive to letter case (\"FREE\" seems to be more spam-like than \"free\"), and\n",
    "* by preserving punctuation (\"you won!\" and \"you won!!!\" can appear in different contexts)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
